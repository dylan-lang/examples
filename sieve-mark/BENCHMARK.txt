Date: Thu, 29 Jun 2000 16:22:40 -0400
From: Eric Kidd <eric.kidd@pobox.com>
To: gd-hackers@gwydiondylan.org
Subject: Rigged benchmarks

I've been benchmarking various programming languages by running the Sieve
of Eratosthenes over the first five million integers.

This is a nicely rigged benchmark, because I can use a
'limited(<simple-vector>, of: <integer>)' in the Dylan version, and generate
some very reasonable code.

All times are the best time, measured in seconds. If a particular
implementation started swapping, I marked it as FAILED. (There was usually
about 60MB of free RAM during these tests.)

These are *not* highly scientific tests.

Caveats:

 * I love Perl and Python--projects in these two languages pay my rent.

 * This benchmark is rigged.
 * C and Dylan are compiled.
 * Python and Perl are interpreted.
 * The Dylan compiler is slow and produces large executables, even when
   shared libraries are used. The executable size is fixable. The speed
   of compilation could be good in *theory* (if Functional Objects'
   implementation of Dylan is indication), but we have a lot of work to do.
 * All caches were warm. This benefits everything but C.
 * GCC flags were identical for C and Dylan.
 * The Dylan benchmarks were run with the OPTIMIZER_HACKING branch in CVS.

Here are my results:

  Five Million Integer Sieve of Eratosthenes
  ==========================================

  Implementation           Seconds
  --------------           -------
  C                           3.90
  Dylan w/o bounds checks     4.33
  Dylan w/ bounds checks      4.35
  Python w/ 'for' loops     FAILED (massive swapping)
  Python w/ 'while' loops   156.83
  Perl 5                    FAILED (bad vector representation?)

Neither of the popular (and otherwise excellent) scripting languages could
run a naive version of the benchmark. I was eventually able to make Python
run by using 'while' loops instead of 'for' loops.

Is there something odd going on with 'for i in range(...):' optimizations
in Python?

So let's try it again on a smaller benchmark:

  Five Hundred Thousand Integer Sieve
  ===================================

  Implementation           Seconds
  --------------           -------
  C                           0.33
  Dylan w/o bounds checks     0.37
  Dylan w/ bounds checks      0.38
  Python w/ 'for' loops      11.40
  Python w/ 'while' loops    15.03
  Perl 5                     24.58

Relative performance:

  * In an absolute best-case scenario, Dylan runs at about 90% the speed
    of C. (Like I said, this benchmark was rigged.)
  * When doing computations with integers and arrays, Python takes about
    35 to 45 times as long as C.
  * When doing computations with integers and arrays, Perl takes about
    75 times as long as C.

It should be noted, however, that Perl does character I/O four times as
fast as our current stream library (according to earlier benchmarks by
Bruce Holt).

Conclusions:

  * You can almost match the performance of C in a very high-level language.
  * Optional type declarations (and a good type inference engine) are just
    as good as static type declarations.[1]
  * Bounds-checking of arrays is nearly free on modern hardware.
  * Python 'for' loops are faster than the equivalent 'while' loop, except
    when they use up all your swap space.
  * Compiled languages are much faster than interpreted languages (of course).

And most importantly:

  * The original Gwydion Group at CMU *really* knows how to write
    powerful optimizers.

Does the Perl compiler do type inferencing?

I'll check all the code into our CVS server if anyone wants it.

Cheers,
Eric

[1] In this example, the Dylan code contained a single type declaration.
